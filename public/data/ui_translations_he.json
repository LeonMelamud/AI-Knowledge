{
  "moreInfo": "מידע נוסף",
  "hideInfo": "הסתר מידע",
  "showMoreInfo": "הצג מידע ותמונה",
  "generatePromptsAndVoice": "יצירת טקסט וקול",
  "noMatchingContent": "לא נמצא תוכן מתאים.",
  "codeExample": "דוגמת קוד:",
  "enterApiKey": "הכנס את מפתח ה-API שלך",
  "enterPrompt": "הכנס את הבקשה שלך",
  "generateText": "צור טקסט",
  "selectVoice": "בחר קול:",
  "enterApiKeyAndPrompt": "אנא הכנס גם מפתח API וגם בקשה.",
  "tokensUsed": "טוקנים בשימוש: {total} (בקשה: {prompt}, השלמה: {completion})",
  "textGenerationError": "אירעה שגיאה בעת יצירת הטקסט. אנא בדוק את הקונסול לפרטים נוספים.",
  "textGenerationUnavailable": "יצירת טקסט אינה זמינה כרגע.",
  "heroTitle": "מאגר הידע של הבינה המלאכותית",
  "knowledge": "ידע",
  "links": "קישורים",
  "specialSections": "סעיפים מיוחדים",
  "hideImage": "הסתר תמונה",
  "showImage": "הצג תמונה",
  "tokenCalculator": "מחשבון טוקנים",
  "enterText": "הכנס טקסט",
  "calculateTokens": "חשב טוקנים",
  "numberOfTokens": "מספר הטוקנים",
  "tokenExplanation": "מודלים של שפה גדולים כמו GPT-4 משתמשים בטוקנים במקום מילים כדי לייצג טקסט באופן יעיל יותר. מילים מפוצלות ליחידות קטנות יותר הנקראות טוקנים, דבר שמאפשר למודל לתפוס טוב יותר דפוסים וקשרים בנתונים. טוקנים מותאמים למודלים אלו ומספקים ייצוג קומפקטי יותר של הטקסט.\n\nהפונקציה getEncoding('gpt2') מהספרייה js-tiktoken מספקת אנקודר שתוכנן במיוחד עבור המודל GPT, שהוא מודל שפה חזק שהוכשר על ידי OpenAI. אנקודר זה ממיר את הטקסט הקלט לרצף של טוקנים שיכול להיות מעובד על ידי המודל GPT. לכל מודל שפה יש ייצוג שונה של טוקנים, כיוון שתהליך הטוקניזציה מפצל את המילים לטוקנים באופן שונה על בסיס קורפוס הנתונים שבו הוכשר המודל.\n\nמכיוון שאנו מתכוונים להשתמש במודל GPT לעיבוד טקסט, אנו משתמשים באנקודר המתאים לו (getEncoding('gpt2')) כדי לחשב את מספר הטוקנים בטקסט הקלט. חשוב לציין שמודלי שפה שונים יהיו להם ייצוגי טוקנים שונים, לכן אם תתכוונו להשתמש במודל אחר, עליכם להשתמש באנקודר המתאים למודל ההוא."
}