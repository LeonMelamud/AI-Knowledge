{
  "moreInfo": "More Info",
  "hideInfo": "Hide Info",
  "showMoreInfo": "Show More and Image",
  "generatePromptsAndVoice": "Generate Prompts and Voice",
  "noMatchingContent": "No matching content found.",
  "codeExample": "Code Example:",
  "enterApiKey": "Enter your API key",
  "enterPrompt": "Enter your prompt",
  "generateText": "Generate Text",
  "selectVoice": "Select Voice:",
  "enterApiKeyAndPrompt": "Please enter both API key and prompt.",
  "tokensUsed": "Tokens used: {total} (Prompt: {prompt}, Completion: {completion})",
  "textGenerationError": "An error occurred while generating text. Please check the console for more details.",
  "textGenerationUnavailable": "Text generation is not available at the moment.",
  "heroTitle": "The AI Knowledge Base",
  "knowledge": "Knowledge",
  "links": "Links",
  "specialSections": "Special Sections",
  "hideImage": "Hide Image",
  "showImage": "Show Image",
  "tokenCalculator": "Token Calculator",
  "enterText": "Enter text",
  "calculateTokens": "Calculate Tokens",
  "numberOfTokens": "Number of tokens",
  "tokenExplanation": "Large Language Models like GPT-4 use tokens instead of words to represent text more efficiently. Words are split into smaller units called tokens, which allow the model to better capture patterns and relationships in the data. Tokens are optimized for these models and provide a more compact representation of the text.\n\nThe getEncoding('gpt2') function from the js-tiktoken library provides an encoder specifically designed for the GPT model, which is a powerful language model trained by OpenAI. This encoder converts the input text into a sequence of tokens that can be processed by the GPT model.",
  "hotNews": "Hot News",
  "viewHotNews": "View Hot News",
  "maintenanceMessage": "Server is under maintenance for cloud LLM services, fork the project from git to play with it locally.",
  "hotNewsDisclaimer": "Information sourced from ThursdAI or similar AI-powered news aggregators."
}
