hot_news:
  - section: "LLMs"
    topics:
      - title: "MiniMax-01: 4 Million Context, 456 Billion Parameters, and Lightning Attention"
        description: |
          This came absolutely from the left field, given that we've seen no prior LLMs from Haulio, the company previously releasing video models with consistent characters. Dropping a massive 456B mixture of experts model (45B active parameters) with such a long context support in open weights, but also with very significant benchmarks that compete with Gpt-4o, Claude and DeekSeek v3 (75.7 MMLU-pro, 89 IFEval, 54.4 GPQA)
          They have trained the model on up to 1M context window and then extended it to 4M with ROPE scaling methods (our coverage of RoPE) during Inference. MiniMax-Text-01 adopts a hybrid architecture that combines Lightning Attention, Softmax Attention and Mixture-of-Experts (MoE) with 45B active parameters.
        images:
          - "minimax01.jpg"
      - title: "Vision, API and Browsing - Minimax-VL-01"
        description: |
          It feels like such a well rounded and complete release, that it highlights just how mature company that is behind it. They have also released a vision version of this model, that includes a 300M param Vision Transformer on top (trained with 512B vision language tokens) that features dynamic resolution and boasts very high DocVQA and ChartQA scores.
          Not only did these two models were released in open weights, they also launched as a unified API endpoint (supporting up to 1M tokens) and it's cheap! $0.2/1M input and $1.1/1M output tokens! AFAIK this is only the 3rd API that supports this much context, after Gemini at 2M and Qwen Turbo that supports 1M as well.
        images:
          - "minimaxvl01.jpg"
  - section: "Voice & Audio"
    topics:
      - title: "Kokoro.js - run the SOTA open TTS now in your browser"
        description: |
          we now have kokoro.js, or npm -i kokoro-js if you will.
          This allows you to install and run Kokoro, the best tiny TTS model, completely within your browser, with a tiny 90MB download and it sounds really good
        links:
          - name: "kokoro-web"
            url: "https://huggingface.co/spaces/webml-community/kokoro-web"
            
      - title: "Hailuo T2A - Emotional text to speech + API"
        description: |
          Hailuo didn't rest on their laurels of releasing a huge context window LLM, they also released a new voice framework (tho not open sourced) this week, and it sounds remarkably good (competing with 11labs)
          They have all the standard features like Voice Cloning, but claim to have a way to preserve the emotional undertones of a voice. They also have 300 voices to choose from and professional effects applied on the fly, like acoustics or telephone filters. (Remember, they have a video model as well, so assuming that some of this is to for the holistic video production)
  - section: "Big Companies & APIs"
    topics:
      - title: "OpenAI adds chatGPT tasks - first agentic feature with more to come!"
        description: |
          We finally get a glimpse of an agentic chatGPT, in the form of scheduled tasks! Deployed to all users, it is now possible to select gpt-4o with tasks, and schedule tasks in the future.
          You can schedule them in natural language, and then will execute a chat (and maybe perform a search or do a calculation) and then send you a notification (and an email!) when the task is done!
          A bit underwhelming at first, as I didn't really find a good use for this yet, I don't doubt that this is just a building block for something more Agentic to come that can connect to my email or calendar and do actual tasks for me, not just... save me from typing the chatGPT query at "that time"
        images:
          - "agentic.jpg"
      - title: "Mistral CodeStral 25.01 - a new #1 coding assistant model"
        description: |
          An updated Codestral was released at the beginning of the week, and TBH I've never seen the vibes split this fast on a model.
          While it's super exciting that Mistral is placing a coding model at #1 on the LMArena CoPilot's arena, near Claude 3.5 and DeepSeek, the fact that this new model is not released weights is really a bummer (especially as a reference to the paragraph I mentioned on top)
          We seem to be closing down on OpenSource in the west, while the Chinese labs are absolutely crushing it (while also releasing in the open, including Weights, Technical papers).
          Mistral has released this model in API and via a collab with the Continue dot dev coding agent, but they used to be the darling of the open source community by releasing great models!
          Also notable, a very quick new benchmark post release was dropped that showed a significant difference between their reported benchmarks and how it performs on Aider polyglot
        images:
          - "mistral_code.jpg"
  - section: "LLMs"
    topics:
      - title: "Sam Altman releases an ASI blog, multiple OpenAI people switch from AGI to ASI"
        description: "Sam Altman, CEO of OpenAI, published a blog post titled \"Reflections,\" discussing the company's progress towards Artificial General Intelligence (AGI) and their new focus on Artificial Superintelligence (ASI)."
        links:
          - name: "SAM ALTMAN'S BLOG"
            url: "https://blog.samaltman.com/reflections?utm_source=chatgpt.com"
        images:
          - "asi.jpg"
      - title: "NVIDIA updates from CES"
        description: "At CES 2025, NVIDIA made several announcements, including the introduction of the GeForce RTX 50 Series GPUs powered by the new Blackwell architecture, advancements in AI models for robotics and autonomous vehicles, and the unveiling of Project Digits, a compact AI supercomputer."
        links:
          - name: "AP NEWS"
            url: "https://apnews.com/article/nvidia-ces-2025-blackwell-ai-chips-fadab7fc10c1a3e306c0a16448559ad8?utm_source=chatgpt.com"
        images:
          - "nvidia-ces.jpg"
      - title: "XAI - released Grok as a standalone app in iOS + Grok 3 finished pre-training"
        description: "XAI has released Grok as a standalone app on iOS, and Grok 3 has completed its pre-training phase."
        links:
          - name: "X"
            url: "https://x.com/elonmusk/status/1875357350393246114"
        images:
          - "grok3.jpg"
  - section: "Sound & Video"
    topics:
      - title: "NVIDIA Cosmos - World Foundation Models"
        description: "NVIDIA introduced Cosmos, a platform featuring World Foundation Models aimed at advancing autonomous mobility and robotics."
        links:
          - name: "Nvidia"
            url: "https://www.nvidia.com/en-eu/ai/cosmos/"
      - title: "Kokoro - #1 TTS with Apache 2 license"
        description: "Kokoro has been recognized as the leading Text-to-Speech (TTS) system available under the Apache 2 license."
      - title: "Baidu - Hallo 3 - generative portraits"
        description: "Baidu has introduced Hallo 3, a model capable of generating portraits."
      - title: "ByteDance - LatentSync lip syncing model"
        description: "ByteDance has developed LatentSync, a model designed for lip-syncing applications."

      - title: "Stability - SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images"
        description: "Stability AI has released SPAR3D, a model for stable point-aware reconstruction of 3D objects from single images."
        links:
          - name: "github"
            url: "https://github.com/Stability-AI/stable-point-aware-3d"
        images:
          - "turntable.gif"
  - section: "Gemini 2.0 Flash Thinking Experimental"
    topics:
      - title: "Gemini 2.0 Flash Thinking Experimental"
        description: "Google introduces Gemini 2.0 Flash Thinking Experimental model with advanced capabilities including multimodal understanding, reasoning, and coding. Features include: Input/Output pricing ($0.00 for <128K tokens), best for multimodal understanding, reasoning, and coding tasks. The model excels at reasoning over complex problems and showing the thinking process. Knowledge cutoff: Aug 2024, Rate limits: 10 RPM, Latency: Medium."
        images:
          - "2.0-flash-TE.jpg"
  - section: "LLMs"
    topics:
      - title: "OpenAI releases new o1 + API access"
        description: "OpenAI has released their new o1 model with API access."
        links:
          - name: "OpenAI"
            url: "https://openai.com/index/o1-and-new-tools-for-developers/"
      - title: "Microsoft makes CoPilot Free!"
        images:
          - "copilot-free-header.jpg"
        description: "Microsoft announces that CoPilot is now available for free."
        links:
          - name: "copilot-free"
            url: "https://github.blog/news-insights/product-news/github-copilot-in-vscode-free/"
  - section: "Open Source LLMs"
    topics:
      - title: "Meta Apollo 7B - LMM w/ SOTA video understanding"
        links:
          - name: "HF"
            url: "https://huggingface.co/FreedomIntelligence/Apollo-7B"
          - name: "HF"
        description: "Meta releases Apollo 7B, a multimodal LLM with state-of-the-art video understanding capabilities"
        
      - title: "Microsoft Phi-4 - 14B SLM"
        links:
          - name: "Blog"
            url: "https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090"
        description: "Microsoft releases Phi-4, a 14B parameter small language model"
      - title: "Cohere Command R 7B"
        links:
          - name: "Blog"
            url: "https://cohere.com/blog/command-r7b"
        description: "Cohere releases Command R, a 7B parameter model"
      - title: "Falcon 3 - series of models"
        links:
          - name: "HF"
            url: "https://huggingface.co/blog/falcon3"
        description: "TII releases Falcon 3 series of models"

  - section: "Voice & Audio"
    topics:
      - title: "OpenAI realtime audio improvements"
        description: "OpenAI has made significant improvements to their realtime audio processing capabilities."
        links:
          - name: "docs"
            url: "https://platform.openai.com/docs/guides/speech-to-text"
      
      - title: "11labs new Flash 2.5 model - 75ms generation"
        description: "11labs has released their new Flash 2.5 model with ultra-fast 75ms generation time."
        links:
          - name: "X"
            url: "https://twitter.com/elevenlabsio"

  - section: "IBM Updates"
    topics:
      - title: "IBM updates Granite 3.1 + embedding models"
        description: "IBM has updated Granite 3.1 and their embedding models with significant improvements."
        links:
          - name: "HF"
            url: "https://www.ibm.com/new/announcements/ibm-granite-3-1-powerful-performance-long-context-and-more"
  - section: "Vision & Video"
    topics:
      - title: "Google releases Veo 2 - beating SORA by most accounts"
        description: "Google's Veo 2 outperforms OpenAI's SORA in most benchmarks."

      - title: "HunyuanVideo distilled with FastHunyuan down to 6 steps"
        description: "HunyuanVideo has been optimized with FastHunyuan, reducing the process to just 6 steps."
        links:
          - name: "Git"
            url: "https://github.com/Tencent/HunyuanVideo"

      - title: "Kling 1.6"
        description: "Kling releases version 1.6 with improved capabilities."
        links:
          - name: "X"
            url: "https://x.com/Kling_ai?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor"

  - section: "Google's Gemini 2.0 Launch"
    topics:
      - title: "Introducing Gemini 2.0: The New AI Model for the Agentic Era"
        images:
          - "gemini-2-launch.jpg"
        description: "Google has unveiled Gemini 2.0, marking a significant leap in AI capabilities focused on agentic behavior. The new model demonstrates enhanced reasoning, planning, and autonomous decision-making abilities. Key features include improved context understanding, better task planning, and more reliable execution of complex multi-step operations. Gemini 2.0 shows particular strength in autonomous problem-solving and adaptive learning scenarios."
        links:
          - name: "Gemini 2.0 Official Launch"
            url: "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#ceo-message"
  - section: "OpenAI's Latest Innovations"
    topics:
      - title: "OpenAI O1 & Pro Tier Launch"
        images:
          - "openai-o1-pro.jpg"
        description: "O1 is out of preview, now smarter, faster, multimodal, and integrated into ChatGPT. For heavy usage, ChatGPT Pro ($200/month) offers unlimited calls and O1 Pro Mode for harder reasoning tasks."

  - section: "Open Source AI Advancements"
    topics:
      - title: "Video & Audio Open Source Breakthrough"
        images:
          - "tencent-hyvideo.jpg"
        description: "Tencent's HYVideo outperforms Runway and Luma, bringing high-quality video generation to open source. Fishspeech 1.5 challenges top TTS providers, making near-human voice available for free research."
      
      - title: "Decentralized LLM Training Success"
        images:
          - "decentralized-llm.jpg"
        description: "Nous Research's DiStRo (15B) and Prime Intellect's INTELLECT-1 (10B) prove you can train giant LLMs across decentralized nodes globally. Performance is on par with centralized setups."

  - section: "Google's AI Breakthroughs"
    topics:
      - title: "Genie 2 & WorldLabs Revolution"
        images:
          - "google-genie-worldlabs.jpg"
        description: "Generating fully interactive 3D worlds from a single image, pushing boundaries in embodied AI and simulation. Google's GenCast also sets a new standard in weather prediction, beating supercomputers in accuracy and speed."

  - section: "Open Source AI Breakthroughs"
    topics:
      - title: "Revolutionary Open Source Models Challenge Industry Giants"
        images:
          - "open-source-reasoning.jpg"
        description: "A groundbreaking development in open source AI as the first reasoning model that can run locally outperforms a 405B model and approaches O1 metrics in some areas. Additionally, Nvidia's innovative Hymba 1.5B hybrid approach demonstrates superior performance over Qwen 1.5B with 6-12x less training. Allen AI's release of Olmo 2 has set a new standard as the best fully open source LLM, complete with data release despite absence of WandB logs."
        links:
          - name: "Olmo 2 Blog"
            url: "https://blog.allenai.org/olmo-2"
          - name: "Olmo 2 HuggingFace"
            url: "https://huggingface.co/allenai/OLMo-2-1124-7B-SFT"

  - section: "Gemini's Comeback"
    topics:
      - title: "Google's Gemini Exp 1121 Reclaims Top Position"
        images:
          - "gemini-exp-1121.jpg"
        description: "In a dramatic turn of events, Google's experimental model Gemini Exp 1121 has either reclaimed or shared the #1 position in AI rankings, just a day after ChatGPT had taken the lead from the previous Gemini version."

  - section: "BFL's Revolutionary Art Tools"
    topics:
      - title: "Black Forest Labs Launches Flux.1 Creative Suite"
        images:
          - "flux-tools.jpg"
        description: "Black Forest Labs has unveiled Flux.1 Tools, a comprehensive suite for AI artists including FLUX.1 Fill for In/Out painting, FLUX.1 Depth/Canny for structural guidance using depth maps or canny edges, and FLUX.1 Redux for image variation and restyling. While these concepts aren't new to the AI art community, BFL's implementation represents a significant advancement, achieving state-of-the-art results on image variation benchmarks. These tools, previously adapted from models like SDXL, have been refined to deliver superior performance."

  - section: "Claude's Big Week"
    topics:
      - title: "Claude's Big Week: Computer Control, Code Wizardry, and the Missing Opus"
        images:
          - "claude-big-week.jpg"
        description: "Anthropic dominated the headlines with updates and announcements, including the new Claude Sonnet 3.5. The model shows impressive results on coding benchmarks, surpassing OpenAI's O1 preview on some tests. With a doubled context window from 4K to 8K, it particularly excels in code tasks despite mixed results in scientific reasoning and writing tasks."

  - section: "Claude Sonnet Performance"
    topics:
      - title: "Claude Sonnet 3.5: Coding Prodigy or Benchmark Buster?"
        images:
          - "claude-sonnet-benchmarks.jpg"
        description: "The new Sonnet model demonstrates exceptional performance on coding benchmarks like Aider and Swe-bench. While showing mixed results on other benchmarks, it particularly dominates in code tasks, showcasing impressive capabilities in code editing and refactoring benchmarks."

  - section: "Anthropic Updates"
    topics:
      - title: "Haiku 3.5 and the Vanishing Opus: Anthropic's Cryptic Clues"
        images:
          - "claude-haiku-opus.jpg"
        description: "Anthropic announced Claude 3.5 Haiku with availability promised by month-end. Meanwhile, the anticipated Opus model has disappeared from their website, leading to speculation about whether Sonnet might be a rebranded Opus."

  - section: "Historic Nobel Prizes in AI"
    topics:
      - title: "Geoffrey Hinton and John Hopfield Awarded Nobel Prize in Physics"
        images:
          - "hinton-hopfield-nobel.jpg"
        description: "In a historic week for AI, Geoffrey Hinton and John Hopfield were awarded the Nobel Prize in Physics for their foundational work on neural networks. Hinton, often called the 'grandfather of modern AI,' and Hopfield were recognized for their contributions that paved the way for modern deep learning, including concepts like back propagation and Boltzmann machines. This marks the first time that AI researchers have been awarded a Nobel Prize, signifying the field's growing importance and impact on science and society."
        links:
          - name: "Nobel Prize Announcement"
            url: "https://www.nobelprize.org/prizes/physics/2024/summary/"
  
  - section: "Meta's MovieGen: A Leap in AI-Generated Video"
    topics:
      - title: "Meta Unveils MovieGen: Advanced AI Video Generation"
        images:
          - "meta-moviegen.jpg"
        description: "Meta has introduced MovieGen, a groundbreaking AI model for video generation. This 30B parameter model can create long, high-definition videos with various aspect ratios, personalized elements, and accompanying audio, all from text and image prompts. Notable features include impressive audio generation and personalization capabilities. While not yet publicly released, MovieGen represents a significant advancement in AI-generated content, potentially rivaling OpenAI's SORA."
        links:
          - name: "Meta AI Blog Post"
            url: "https://ai.meta.com/blog/"
          - name: "MovieGen"
            url: "https://ai.meta.com/research/movie-gen/"
        key_points:
          - "30B parameter model for advanced video generation"
          - "Generates high-quality audio to accompany videos"
          - "Personalization feature for realistic character insertion"
          - "Not yet publicly released or widely available"
          - "Potential ethical concerns regarding misuse and deepfake creation"
  - section: "Black Forest Labs - Flux 1.1 Pro"
    topics:
      - title: "Black Forest Labs Introduces Flux 1.1 Pro"
        images:
          - "flux1.1pro_0.jpg"
          - "flux1.1pro_1.jpg"
        description: "Black Forest Labs has released Flux 1.1 Pro, a significant upgrade to their text-to-image model. This new model offers six times faster image generation compared to its predecessor, Flux 1.0 Pro, while also enhancing image quality, prompt adherence, and diversity. Flux 1.1 Pro is codenamed 'blueberry' and has been tested to outperform other models on the Artificial Analysis image arena leaderboard. It is available through various platforms including Fal, Together, Replicate, and Freepik, and via the Black Forest Labs API at a competitive pricing of 4 cents per image generation."
        links:
          - name: "Announcement"
            url: "https://blackforestlabs.ai/announcing-flux-1-1-pro-and-the-bfl-api/"
          - name: "Try on Replicate"
            url: "https://replicate.com/"
          - name: "Try on Fal"
            url: "https://fal.ai/dashboard"
  - section: "OpenAI ChatGPT Canvas"
    topics:
      - title: "OpenAI ChatGPT Canvas - A New Way to Interact with ChatGPT"
        images:
          - "canvan-open-ai.jpg"
        description: "OpenAI's ChatGPT Canvas is a groundbreaking interface that transforms ChatGPT into a creative partner for writing and coding projects. It offers a dedicated, visual workspace where users can edit text or code directly, receive inline feedback, and use shortcuts for tasks like adjusting length, debugging code, and adding polish. Trained with synthetic data, the GPT-4o model in Canvas improves accuracy by 30%. Currently in beta, Canvas is set to revolutionize AI collaboration."
        links:
          - name: "Announcement"
            url: "https://openai.com/blog/chatgpt-canvas"
  - section: "Open Source LLMs"
    topics:
      - title: "Alibaba Qwen 2.5 models drop"
        images:
          - "qwen2.5-coder.jpg"
        description: "Qwen 2.5 Math and Qwen 2.5 Code"

  - section: "Big CO LLMs + APIs"
    topics:
      - title: "OpenAI O1 results from LMsys"
        images:
          - "o1.jpg"
        description: "New KING LLM in town, vibe checks confirm"
        links:
          - name: "Thread"
            url: "https://x.com/OpenAI/status/1836846202182131776"
  - section: "Vision & Video"
    topics:
      - title: "Text-2-video over API announcements"
        description: "Runway, DreamMachine & Kling announce text-2-video over API"
        links:
          - name: "Runway"
            url: "https://x.com/runwayml/status/1835670564825944265"
          - name: "DreamMachine"
            url: " https://x.com/LumaLabsAI/status/1835742651662139529"
