concepts:
  - id: basics
    title: יסודות הבינה המלאכותית
    items:
      - name: בינה מלאכותית (AI)
        shortDescription: תחום במדעי המחשב העוסק ביצירת מערכות חכמות שיכולות לבצע משימות הדורשות אינטליגנציה אנושית.
        fullDescription: |
          בינה מלאכותית מתייחסת ליצירת מערכות ממוחשבות המסוגלות לבצע משימות הדורשות אינטליגנציה אנושית. 
          זה כולל תחומים כמו:
          - עיבוד שפה טבעית
          - ראייה ממוחשבת
          - קבלת החלטות
          - פתרון בעיות מורכבות
          AI משלבת מגוון של טכניקות, כולל למידת מכונה, עיבוד שפה טבעית, וחשיבה לוגית.

      - name: למידת מכונה (Machine Learning)
        shortDescription: תחום ב-AI המתמקד באלגוריתמים שמשתפרים באופן אוטומטי דרך ניסיון.
        fullDescription: |
          למידת מכונה היא תחום בבינה מלאכותית המתמקד באלגוריתמים ומודלים סטטיסטיים 
          שמערכות מחשב משתמשות בהם כדי לבצע משימה מבלי להשתמש בהוראות מפורשות, 
          אלא תוך הסתמכות על דפוסים והסקה. זוהי הבסיס למרבית היישומים המודרניים של AI.
        codeExample: |
          from sklearn.model_selection import train_test_split
          from sklearn.linear_model import LinearRegression
          import numpy as np

          # Create sample data
          X = np.random.rand(100, 1)
          y = 2 * X + 1 + np.random.randn(100, 1) * 0.1

          # Split into training and testing data
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

          # Create and train the model
          model = LinearRegression()
          model.fit(X_train, y_train)

          # Evaluate the model
          score = model.score(X_test, y_test)
          print(f"Model accuracy: {score}")

      - name: רשתות עצביות (Neural Networks)
        shortDescription: מודלים מתמטיים המבוססים על מבנה המוח האנושי.
        fullDescription: |
          רשתות עצביות הן מודלים מתמטיים המבוססים על מבנה ופעולת המוח האנושי. 
          הן מורכבות משכבות של "נוירונים" מלאכותיים המחוברים זה לזה. 
          כל חיבור יש לו משקל שמתכוונן במהלך תהליך הלמידה. 
          רשתות עצביות יכולות ללמוד לזהות דפוסים מורכבים בנתונים ומשמשות במגוון רחב של יישומי AI.
        codeExample: |
          import tensorflow as tf

          model = tf.keras.Sequential([
              tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),
              tf.keras.layers.Dense(64, activation='relu'),
              tf.keras.layers.Dense(1)
          ])

          model.compile(optimizer='adam', loss='mse')

      - name: למידה עמוקה (Deep Learning)
        shortDescription: תת-תחום של למידת מכונה המשתמש ברשתות עצביות עם שכבות רבות.
        fullDescription: |
          למידה עמוקה היא תת-תחום של למידת מכונה המתמקד ברשתות עצביות עם מספר רב של שכבות נסתרות. 
          טכניקה זו מאפשרת למודלים ללמוד ייצוגים מורכבים של נתונים באופן היררכי. 
          למידה עמוקה עומדת מאחורי התקדמויות משמעותיות בתחומים כמו עיבוד שפה טבעית, 
          ראייה ממוחשבת, זיהוי דיבור ועוד.

  - id: advanced_concepts
    title: מושגים מתקדמים
    items:
      - name: פרמטרים של מודל
        shortDescription: הערכים המספריים שהמודל משתמש בהם לביצוע חישובים, כולל משקולות והטיות.
        fullDescription: |
          פרמטרים של מודל הם הערכים המתכווננים במהלך תהליך האימון של המודל. הם כוללים:
          - משקולות: מייצגות את החוזק של הקשרים בין היחידות ברשת.
          - הטיות: מאפשרות למודל להזיז את פונקציית ההפעלה.
          מספר הפרמטרים משפיע על יכולת הלמידה של המודל ועל הסיכון ל-overfitting.

      - name: גודל מודל
        shortDescription: מתייחס למספר הפרמטרים שהמודל מכיל. מודלים גדולים יכולים ללמוד תבניות מורכבות יותר.
        fullDescription: |
          גודל המודל מחושב על ידי סכימה של כל הפרמטרים במודל. לדוגמה:
          - ברשת עצבית פשוטה: מספר הפרמטרים = (מספר הקלטים * מספר הנוירונים בשכבה הנסתרת) + (מספר הנוירונים בשכבה הנסתרת * מספר הפלטים) + (מספר ההטיות)
          - במודל Transformer: גודל המודל מושפע מגורמים כמו מספר השכבות, גודל המילון, ואורך הרצף המקסימלי.
          מודלים גדולים יותר (כמו GPT-3 עם 175 מיליארד פרמטרים) יכולים ללמוד תבניות מורכבות יותר, אך דורשים יותר משאבי חישוב ונתונים לאימון.

      - name: מנגנון קשב (Attention Mechanism)
        shortDescription: מנגנון המאפשר למודל להתמקד בחלקים שונים של הקלט בזמן עיבוד.
        fullDescription: |
          מנגנון ה-Attention מאפשר למודל להקצות משקל שונה לחלקים שונים של הקלט בזמן עיבוד. 
          זה מאפשר למודל "להתמקד" במידע הרלוונטי ביותר למשימה הנוכחית. 
          מנגנון זה היה פריצת דרך משמעותית בתחום עיבוד השפה הטבעית, 
          ומשמש בארכיטקטורות מתקדמות כמו Transformer.

      - name: Transformers
        shortDescription: ארכיטקטורת מודל המבוססת על מנגנון ה-Attention, משמשת בעיקר לעיבוד שפה טבעית.
        fullDescription: |
          Transformers הם ארכיטקטורת מודל שהוצגה ב-2017 ומבוססת על מנגנון ה-Attention. 
          הם מאפשרים עיבוד מקבילי של הקלט, מה שמוביל לאימון מהיר יותר ויכולת לעבד רצפים ארוכים. 
          Transformers עומדים בבסיס מודלים מתקדמים רבים לעיבוד שפה טבעית כמו BERT, GPT, ו-T5.

  - id: techniques
    title: טכניקות מתקדמות
    items:
      - name: למידה מעבירה (Transfer Learning)
        shortDescription: שימוש במודל שאומן על משימה אחת כבסיס למשימה אחרת.
        fullDescription: |
          Transfer Learning היא טכניקה שבה מודל שאומן על משימה אחת משמש כנקודת התחלה למודל במשימה אחרת, קשורה. 
          זה חוסך זמן ומשאבים באימון ויעיל במיוחד כשיש מעט נתונים למשימה החדשה. 
          לדוגמה, מודל שאומן לזהות חתולים יכול לשמש כבסיס למודל שמזהה כלבים.

      - name: למידת Few-shot
        shortDescription: היכולת של מודל ללמוד ממספר קטן של דוגמאות.
        fullDescription: |
          Few-shot Learning מתייחס ליכולת של מודל ללמוד משימה חדשה ממספר קטן מאוד של דוגמאות מתויגות. 
          זה חשוב במצבים שבהם קשה להשיג כמויות גדולות של נתונים מתויגים. 
          טכניקות Few-shot Learning כוללות גישות כמו Metric Learning ו-Meta-Learning.

      - name: RAG (Retrieval-Augmented Generation)
        shortDescription: טכניקה המשלבת אחזור מידע עם יצירת טקסט לשיפור הדיוק והרלוונטיות של תשובות.
        fullDescription: |
          RAG משלב מנגנון אחזור מידע עם מודל שפה גדול. כאשר המודל מקבל שאילתא:
          1. מנגנון האחזור מוצא מסמכים רלוונטיים ממאגר מידע.
          2. המידע שאוחזר משולב עם השאילתא המקורית.
          3. המודל משתמש במידע המשולב כדי ליצור תשובה.
          זה מאפשר למודל לספק תשובות מדויקות ועדכניות יותר, תוך הסתמכות על מקורות מידע חיצוניים.

      - name: הנדסת פרומפטים (Prompt Engineering)
        shortDescription: עיצוב מדויק של הוראות למודל לקבלת תוצאות רצויות.
        fullDescription: |
          Prompt Engineering היא האמנות והמדע של עיצוב הקלט למודל שפה גדול כדי לקבל את התוצאה הרצויה. 
          זה כולל ניסוח מדויק של השאלה או ההוראה, מתן דוגמאות רלוונטיות, והגדרת הפורמט הרצוי לתשובה. 
          Prompt Engineering יעיל יכול לשפר משמעותית את הביצועים של מודל ללא צורך באימון מחדש.

      - name: כיוונון עדין (Fine-tuning)
        shortDescription: התאמה עדינה של מודל קיים למשימה ספציפית.
        fullDescription: |
          Fine-tuning היא תהליך של לקיחת מודל שאומן מראש (למשל, BERT או GPT) והתאמתו למשימה ספציפית 
          באמצעות אימון נוסף על מערך נתונים קטן יותר וממוקד. זה מאפשר להתאים מודלים גדולים ומורכבים 
          למשימות ספציפיות בצורה יעילה, תוך שימור הידע הכללי שהמודל רכש באימון המקורי.
